{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7b0dad-866b-44b0-a9e5-0c813d21b0a5",
   "metadata": {},
   "source": [
    "# Segment 2 Lab 2\n",
    "\n",
    "## A real world case study\n",
    "\n",
    "We will look at prices of actual products scraped from Amazon\n",
    "\n",
    "We have details of the products, along with key features.\n",
    "\n",
    "We'll first examine the data, then we'll run Regression\n",
    "\n",
    "## DO YOU HAVE PEN & PAPER HANDY??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80f60c-cd64-4948-93b0-4f6c4210b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from items import Item\n",
    "from loaders import ItemLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d628a9-8119-4ca4-b4d9-cf7e5ef8bd9c",
   "metadata": {},
   "source": [
    "# Downloading the Pickle files\n",
    "\n",
    "I've made convenient pkl files with the training and test data for the remaining labs.\n",
    "\n",
    "Sadly, they are a bit too large to go in git. I've uploaded them to Google Drive and you can fetch them here:  \n",
    "https://drive.google.com/drive/folders/1Imh1NNSsVDXkUWpkeape0hTYL1QROCvj?usp=sharing\n",
    "\n",
    "Please download them and place them in the project root directory (i.e. the `tech2ai` directory, the parent of this current directory).\n",
    "\n",
    "If these files are too large for you, please message me and I will make you a smaller dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b526375-9a6d-4096-9bed-1a74917d1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have the pickle files in the tech2ai directory (above this one), you can load in dataset\n",
    "\n",
    "with open('../training_data.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open('../test_data.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598dae0-c8b8-4947-8409-0884c2f1340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = train + test\n",
    "print(f\"There are {len(items):,} items, split into {len(train):,} training and {len(test):,} test points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac4342-a7a6-41a8-b0b7-b18737f4c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[10000].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d1a48-9572-4d87-be14-0a1e7ff6de6d",
   "metadata": {},
   "source": [
    "## An essential first step to all types of Data Science:\n",
    "\n",
    "# Investigate the data!\n",
    "\n",
    "Each item in our dataset has a category, and it has 3 features: weight, rank (best-seller's rank) and timestamp (when was it released)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70fe55-bbb5-47d2-b82f-29b3f8bad4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(set(item.category for item in items))\n",
    "counts = [len([item for item in items if item.category==category]) for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a10b0-8b4f-455c-8e5a-642850aae934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bar chart by category\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(categories, counts, color=\"goldenrod\")\n",
    "plt.title('How many in each category')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(counts):\n",
    "    plt.text(i, v, f\"{v:,}\", ha='center', va='bottom')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649915f4-103e-4017-90cd-ba6dbabdd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "prices = [item.price for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"purple\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b708e-3af4-404d-b7cd-3034422b3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of weights\n",
    "\n",
    "weights = [item.weight for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Weight (ounces)\")\n",
    "plt.xlabel('Weight (ounces)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(weights, rwidth=0.7, color=\"skyblue\", bins=range(0, 2000, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fcc927-8731-4194-8bbb-8a044ca3a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15df01-9d18-4548-a693-7019d785b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy = [item for item in items if item.weight==400000.0][0]\n",
    "heavy.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919e5fa-a087-4d76-b7a3-766bb841347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the price vary with the weight\n",
    "\n",
    "weights = [item.weight for item in items]\n",
    "prices = [item.price for item in items]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(weights, prices, s=0.1, color=\"red\")\n",
    "plt.xlim(0, 3000)\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Investigate correlations')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071701f-f420-42e1-8131-ec6f79939a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the price vary with how high the product ranks in Amazon best seller lists\n",
    "import math\n",
    "ranks = [item.rank for item in items]\n",
    "prices = [item.price for item in items]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(ranks, prices, s=0.1, color=\"green\")\n",
    "plt.xlim(0, 20000)\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Investigate correlations')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639be4b-0a9c-48b1-b507-005161ef3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the price vary with the timestamp - when it was first released\n",
    "\n",
    "when = [item.timestamp for item in items]\n",
    "prices = [item.price for item in items]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(when, prices, s=0.1, color=\"orange\")\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlim(0, 2e9)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('When')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Investigate correlations')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab4c36-27ba-4b3c-8934-e47b0e920bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for machine learning\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from testing import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981073b-9b64-45fe-a498-ef60c0c23c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start our Linear Regression, let's have some fun\n",
    "# Let's make a terrible model that simply guesses the answer!!\n",
    "\n",
    "def guess(item):\n",
    "    return random.randrange(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a6709-8477-4c10-96b0-66c19ddd36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed so that our results can be reproduced\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42423085-bcf7-445b-af9e-ebeef2806b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a useful function I wrote that takes a function to test, and a dataset\n",
    "\n",
    "Tester.test(guess, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43147e6a-8d5f-47bb-aa2b-3e62be4fe86a",
   "metadata": {},
   "source": [
    "## Write this down!\n",
    "\n",
    "## The error from the random model: $359 \n",
    "\n",
    "We will be comparing a few models.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1bab05-c6f5-40a1-90e7-a11d32078fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another amusingly basic model, but perhaps a bit better than the last one!\n",
    "\n",
    "train_prices = [t.price for t in train]\n",
    "train_average = sum(train_prices)/len(train_prices)\n",
    "\n",
    "def guess2(item):\n",
    "    return train_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6e3fc-2a12-42cd-84bb-332be9c1ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(guess2, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee317af-450f-4265-b419-b4fae056ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do linear regression with our features\n",
    "\n",
    "def get_features(item):\n",
    "    return {\n",
    "        \"weight\": item.weight,\n",
    "        \"rank\": item.rank,\n",
    "        \"timestamp\": item.timestamp,\n",
    "        \"is_top_tech\": 1 if item.is_top_tech else 0,\n",
    "        \"is_top_toys\": 1 if item.is_top_toys else 0,\n",
    "        \"price\": item.price\n",
    "    }\n",
    "\n",
    "def list_to_dataframe(items):\n",
    "    features = [get_features(item) for item in items]\n",
    "    df = pd.DataFrame(features)\n",
    "    df['price'] = [item.price for item in items]\n",
    "    return df\n",
    "\n",
    "train_df = list_to_dataframe(train)\n",
    "test_df = list_to_dataframe(test[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce217a2-5082-43db-8060-dbfa14411f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Linear Regression!\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Separate features and target\n",
    "feature_columns = ['weight', 'rank', 'timestamp', \"is_top_tech\", \"is_top_toys\"]\n",
    "\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df['price']\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df['price']\n",
    "\n",
    "# Train a Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef10136-584f-4229-b0be-491991218427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What were the model parameters for our features?\n",
    "\n",
    "for feature, coef in zip(feature_columns, model.coef_):\n",
    "    print(f\"{feature}: {coef:.7f}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8aef9b-b5fb-4798-bf06-535facfa3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict price for a new item\n",
    "\n",
    "def linear_regression_pricer(item):\n",
    "    features = get_features(item)\n",
    "    del features[\"price\"]\n",
    "    features_df = pd.DataFrame([features])\n",
    "    return model.predict(features_df)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad41c20-f2ba-4e42-b0a8-4f470d7bb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "\n",
    "Tester.test(linear_regression_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a5634-234f-4efc-beee-6214b70f1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a short description of each item - perhaps we would do better to train a model on this text?\n",
    "# This is the start of \"natural language processing\" or NLP\n",
    "\n",
    "train[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345f4f2-914d-4bda-a400-377d82c9c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next few models, we prepare our documents and prices\n",
    "\n",
    "prices = np.array([float(item.price) for item in train])\n",
    "documents = [item.text for item in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547eda3-8d9d-4a04-8f7b-e40efb653bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc69b3-cc16-40ad-92fc-63fd63d2a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CountVectorizer\n",
    "# This changes a paragraph of text into a list of numbers, i.e. a vector\n",
    "# How does it do that? It just counts the number of times words appear!\n",
    "\n",
    "np.random.seed(42)\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b93b9-10ca-4933-8a88-83b3ade2358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the 1,000 most common words that it picked, not including \"stop words\":\n",
    "\n",
    "selected_words = vectorizer.get_feature_names_out()\n",
    "print(f\"Number of selected words: {len(selected_words)}\")\n",
    "print(\"Selected words:\", selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a962e-99ce-4fd0-83a5-fae3fac5e426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5a777-4d4d-4db1-9291-7595a0c79cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2eecc-90a5-4936-a521-80d7241dfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a model to use this for prediction\n",
    "\n",
    "def bag_of_words(item):\n",
    "    x = vectorizer.transform([item.text])\n",
    "    return max(regressor.predict(x)[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23f035-fcae-4dff-8c3c-da351086c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(bag_of_words, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ace02-2d36-4e13-8960-2eac02c8c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the powerful Random Forest regression\n",
    "\n",
    "subset=15_000\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=4)\n",
    "rf_model.fit(X[:subset], prices[:subset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4eaa9-2330-488a-a0a0-deaeb5180140",
   "metadata": {},
   "source": [
    "## Random Forest model\n",
    "\n",
    "The Random Forest is a type of \"**ensemble**\" algorithm, meaning that it combines many smaller algorithms to make better predictions.\n",
    "\n",
    "It uses a very simple kind of machine learning algorithm called a **decision tree**. A decision tree makes predictions by examining the values of features in the input. Like a flow chart with IF statements. Decision trees are very quick and simple, but they tend to overfit.\n",
    "\n",
    "In our case, the \"features\" are the elements of the Vector - in other words, it's the number of times that a particular word appears in the product description.\n",
    "\n",
    "So you can think of it something like this:\n",
    "\n",
    "**Decision Tree**  \n",
    "\\- IF the word \"TV\" appears more than 3 times THEN  \n",
    "-- IF the word \"LED\" appears more than 2 times THEN  \n",
    "--- IF the word \"HD\" appears at least once THEN  \n",
    "---- Price = $500\n",
    "\n",
    "\n",
    "With Random Forest, multiple decision trees are created. Each one is trained with a different random subset of the data, and a different random subset of the features. You can see above that we specify 100 trees, which is the default.\n",
    "\n",
    "Then the Random Forest model simply takes the average of all its trees to product the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1cb03-6d5d-4080-b8d8-a058bc633fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(item):\n",
    "    x = vectorizer.transform([item.text])\n",
    "    return max(0, rf_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97632f-2131-4af9-a59b-d9cdec7dfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(random_forest, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a131e-a137-45db-b083-b24289f6695f",
   "metadata": {},
   "source": [
    "## Introducing XGBoost\n",
    "\n",
    "Like Random Forest, XGBoost is also an ensemble model that combines multiple decision trees.\n",
    "\n",
    "But unlike Random Forest, XGBoost builds one tree after another, with each next tree correcting for errors in the prior trees, using 'gradient descent'.\n",
    "\n",
    "It's much faster than Random Forest, so we can run it for the full dataset, and it's typically better at generalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d406d-3d07-4785-ba9b-d6ff19daf1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=4, learning_rate=0.4)\n",
    "xgb_model.fit(X, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367bfe86-4ae1-4a37-87c9-c7401cd79bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_boost(item):\n",
    "    x = vectorizer.transform([item.text])\n",
    "    return max(0, xgb_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4399c-4416-49df-ab30-2c1fcb9a7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(xg_boost, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c8b86-e2ed-4fff-874e-0fd1d9e84aa6",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Try engineering more features\n",
    "\n",
    "Try different models from traditional machine learning, such as Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cce3f2-7139-486b-b6e6-c5769ec2f98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3fdcf-cd4f-4bbe-9f85-b0538a1eafd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
