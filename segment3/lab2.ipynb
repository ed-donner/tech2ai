{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6019bd07-db6c-4065-a54b-8963996e944e",
   "metadata": {},
   "source": [
    "# Segment 3 Lab 2\n",
    "\n",
    "Understanding a Large Language Model\n",
    "\n",
    "This is also available at this colab:\n",
    "\n",
    "https://colab.research.google.com/drive/10LJw_o08sBaaeJxCrLWo2ypbdFRMBtjV#scrollTo=Z-Scxg24RXeI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4418e-ea2c-459d-ab99-a794a370dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd47672-7b32-4fcc-8d12-484c480e6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e20a6b-505a-4b23-86a3-d72b1afaa527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264c5d8-4546-4d22-96a6-77c0332c7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "import math\n",
    "\n",
    "class TokenPredictor:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.client = OpenAI()\n",
    "        self.messages = []\n",
    "        self.predictions = []\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def predict_tokens(self, prompt: str, max_tokens: int = 100) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Generate text token by token and track prediction probabilities.\n",
    "        Returns list of predictions with top token and alternatives.\n",
    "        \"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0,  # Use temperature 0 for deterministic output\n",
    "            logprobs=True,\n",
    "            seed=42,\n",
    "            top_logprobs=3,  # Get top 3 token predictions\n",
    "            stream=True  # Stream the response\n",
    "        )\n",
    "        \n",
    "        predictions = []\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                token = chunk.choices[0].delta.content\n",
    "                logprobs = chunk.choices[0].logprobs.content[0].top_logprobs\n",
    "                logprob_dict = {item.token: item.logprob for item in logprobs}\n",
    "                \n",
    "                # Get top predicted token and probability\n",
    "                top_token = token\n",
    "                top_prob = logprob_dict[token]\n",
    "                \n",
    "                # Get alternative predictions\n",
    "                alternatives = []\n",
    "                for alt_token, alt_prob in logprob_dict.items():\n",
    "                    if alt_token != token:\n",
    "                        alternatives.append((alt_token, math.exp(alt_prob)))\n",
    "                alternatives.sort(key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                prediction = {\n",
    "                    'token': top_token,\n",
    "                    'probability': math.exp(top_prob),\n",
    "                    'alternatives': alternatives[:2]  # Keep top 2 alternatives\n",
    "                }\n",
    "                predictions.append(prediction)\n",
    "                \n",
    "        return predictions\n",
    "\n",
    "def create_token_graph(model_name:str, predictions: List[Dict]) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Create a directed graph showing token predictions and alternatives.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    G.add_node(\"START\", \n",
    "               token=model_name,\n",
    "               prob=\"START\",\n",
    "               color='lightgreen',\n",
    "               size=4000)\n",
    "    \n",
    "    # First, create all main token nodes in sequence\n",
    "    for i, pred in enumerate(predictions):\n",
    "        token_id = f\"t{i}\"\n",
    "        G.add_node(token_id, \n",
    "                  token=pred['token'],\n",
    "                  prob=f\"{pred['probability']*100:.1f}%\",\n",
    "                  color='lightblue',\n",
    "                  size=6000)\n",
    "        \n",
    "        if i == 0:\n",
    "            G.add_edge(\"START\", token_id)\n",
    "        else:\n",
    "            G.add_edge(f\"t{i-1}\", token_id)\n",
    "    \n",
    "    # Then add alternative nodes with a different y-position\n",
    "    last_id = None\n",
    "    for i, pred in enumerate(predictions):\n",
    "        parent_token = \"START\" if i == 0 else f\"t{i-1}\"\n",
    "        \n",
    "        # Add alternative token nodes slightly below main sequence\n",
    "        for j, (alt_token, alt_prob) in enumerate(pred['alternatives']):\n",
    "            alt_id = f\"t{i}_alt{j}\"\n",
    "            G.add_node(alt_id,\n",
    "                      token=alt_token,\n",
    "                      prob=f\"{alt_prob*100:.1f}%\",\n",
    "                      color='lightgray',\n",
    "                      size=6000)\n",
    "            \n",
    "            # Add edge from main token to its alternatives only\n",
    "            G.add_edge(parent_token, alt_id)\n",
    "            last_id = parent_token\n",
    "            \n",
    "\n",
    "    G.add_node(\"END\", \n",
    "               token=\"END\",\n",
    "               prob=\"100%\",\n",
    "               color='red',\n",
    "               size=6000)\n",
    "    G.add_edge(last_id, \"END\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "def visualize_predictions(G: nx.DiGraph, figsize=(14, 150)):\n",
    "    \"\"\"\n",
    "    Visualize the token prediction graph with vertical layout and alternating alternatives.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create custom positioning for nodes\n",
    "    pos = {}\n",
    "    spacing_y = 10  # Vertical spacing between main tokens\n",
    "    spacing_x = 5  # Horizontal spacing for alternatives\n",
    "    \n",
    "    # Position main token nodes in a vertical line\n",
    "    main_nodes = [n for n in G.nodes() if '_alt' not in n]\n",
    "    for i, node in enumerate(main_nodes):\n",
    "        pos[node] = (0, -i * spacing_y)  # Center main tokens vertically\n",
    "    \n",
    "    # Position alternative nodes to left and right of main tokens\n",
    "    for node in G.nodes():\n",
    "        if '_alt' in node:\n",
    "            main_token = node.split('_')[0]\n",
    "            alt_num = int(node.split('_alt')[1])\n",
    "            if main_token in pos:\n",
    "                # Place first alternative to left, second to right\n",
    "                x_offset = -spacing_x if alt_num == 0 else spacing_x\n",
    "                pos[node] = (x_offset, pos[main_token][1] + 0.05)\n",
    "    \n",
    "    # Draw nodes\n",
    "    node_colors = [G.nodes[node]['color'] for node in G.nodes()]\n",
    "    node_sizes = [G.nodes[node]['size'] for node in G.nodes()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes)\n",
    "\n",
    "    # Draw all edges as straight lines\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, arrowsize=20, alpha=0.7)\n",
    "    \n",
    "    # Add labels with token and probability\n",
    "    labels = {node: f\"{G.nodes[node]['token']}\\n{G.nodes[node]['prob']}\"\n",
    "              for node in G.nodes()}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=14)\n",
    "    \n",
    "    plt.title(\"Token prediction.\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Adjust plot limits to ensure all nodes are visible\n",
    "    margin = 8\n",
    "    x_values = [x for x, y in pos.values()]\n",
    "    y_values = [y for x, y in pos.values()]\n",
    "    plt.xlim(min(x_values) - margin, max(x_values) + margin)\n",
    "    plt.ylim(min(y_values) - margin, max(y_values) + margin)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402c7c8-e86b-42c9-8be4-5ac44cb7ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o\"\n",
    "\n",
    "predictor = TokenPredictor(model_name)\n",
    "\n",
    "# Generate predictions\n",
    "# prompt = \"How would you describe the color blue to someone who has never been able to see, in no more than 3 sentences.\"\n",
    "prompt = \"Estimate exactly how much this product costs from this description; reply with your dollar estimate with a very short explanation:\\nOEM AC Compressor w/A/C Repair Kit For Ford F150 F-150 V8 & Lincoln Mark LT 2007 2008 - BuyAutoParts NEW\\nAs one of the world's largest automotive parts suppliers, our parts are trusted every day by mechanics and vehicle owners worldwide. This A/C Compressor and Components Kit is manufactured and tested to the strictest OE standards for unparalleled performance. Built for trouble-free ownership and 100% visually inspected and quality tested, this A/C Compressor and Components Kit is backed by our 100% satisfaction guarantee. Guaranteed Exact Fit for easy installation 100% BRAND NEW, premium ISO/TS 16949 quality - tested to meet or exceed OEM specifications Engineered for superior durability, backed by industry-leading unlimited-mileage warranty Included in this K\"\n",
    "predictions = predictor.predict_tokens(prompt)\n",
    "\n",
    "# Create and visualize graph\n",
    "G = create_token_graph(model_name, predictions)\n",
    "visualize_predictions(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f12c9-1484-4234-a3d2-393bb298a72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415a2fe-309b-42a2-913c-59fee090deb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
