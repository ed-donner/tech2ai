{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06c733a-1124-44b5-a634-37d0887fdfe6",
   "metadata": {},
   "source": [
    "# The Second Agent - estimate the actual value of a product\n",
    "\n",
    "## RAG (Retrieval Augmented Generation) based on a dataset of 400,000 scraped Amazon products\n",
    "\n",
    "#### For our 2nd agent, we will be asking DeekSeek to estimate the price of one of our deals - and we will give it a hand.\n",
    "\n",
    "It turns out that LLMs are really good at this! Out of the box, GPT-4o is off by an average of \\$76.\n",
    "\n",
    "But we can do even better: we'll provide it with some context, in the form of 5 similar products from our training dataset\n",
    "\n",
    "Again I'll be going quite quickly through this - the idea is for you to run this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db71ba5-55a8-48b7-97d5-9db8dc872837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from items import Item\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from testing import Tester\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044d040-e467-4463-a3a5-119939ca8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')\n",
    "DB = \"products_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cb7f1-41f7-4df8-95fa-f3143b4ce312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to HuggingFace\n",
    "# If you don't have a HuggingFace account, you can set one up for free at www.huggingface.co\n",
    "# And then add the HF_TOKEN to your .env file as explained in the project README\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(token=hf_token, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fbd1f7-619e-49d8-bf1a-209248f1c0e3",
   "metadata": {},
   "source": [
    "# For following along at home:\n",
    "\n",
    "Please download the files train.pkl and test.pkl from this Google Drive folder:  \n",
    "https://drive.google.com/drive/folders/1t0YnoCXCbo2g08uWIOR6TPKR2-6Egb_g?usp=sharing\n",
    "\n",
    "And place them in the parent directory (the directory called agentic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8a0f3-af5c-4f21-8a5f-a4df4fa420ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "\n",
    "with open('../train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47116c8f-7e6b-46a0-90ae-ddf8b220bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(train):,} training items scraped from Amazon, and the first one is {train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43f181-8b51-43c8-9763-599220cf6e66",
   "metadata": {},
   "source": [
    "# Now create a Chroma Datastore\n",
    "\n",
    "Now we will use the free, open-source Vector database Chroma.  \n",
    "We will create a Chroma datastore with 400,000 products from our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba77914-ea9a-4b92-9280-863ee07ca8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744c683-847a-4151-b6e0-56066f1fe4b0",
   "metadata": {},
   "source": [
    "# Introducing the SentenceTransformer Encoding LLM\n",
    "\n",
    "The all-MiniLM is a very useful model from HuggingFace that maps sentences & paragraphs to 384 dimensional vectors and is ideal for tasks like semantic search.\n",
    "\n",
    "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "It can run pretty quickly locally.\n",
    "\n",
    "As an alternative, OpenAI provides a closed-source Embeddings model. Benefits compared to OpenAI embeddings:\n",
    "1. It's free and fast!\n",
    "3. We can run it locally, so the data never leaves our box - might be useful if you're building a personal RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2545a0-e160-41db-8914-f77b1c7eff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32abb023-64b5-40a4-bfc1-e22c3ec31221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in a list of texts, get back a numpy array of vectors\n",
    "\n",
    "vector = model.encode([\"A room full of software engineers\"])[0]\n",
    "print(vector.shape)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f44ea0-9aa3-4812-ab72-f94967b88967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "vector1 = model.encode([\"A room full of software engineers\"])[0]\n",
    "vector2 = model.encode([\"A room full of data scientists\"])[0]\n",
    "cosine_similarity(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04230b9-a0c1-483a-826f-59c905c9637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = model.encode([\"A room full of software engineers\"])[0]\n",
    "vector3 = model.encode([\"A hovercraft full of eels\"])[0]\n",
    "cosine_similarity(vector1, vector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7ea37-0e3b-47c8-a49a-d1e5e58e5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sentence equivalent of the famous King - Man + Woman = Queen\n",
    "\n",
    "room_engineers = model.encode([\"A room full of software engineers\"])[0]\n",
    "room_scientists = model.encode([\"A room full of data scientists\"])[0]\n",
    "engineers = model.encode([\"software engineers\"])[0]\n",
    "scientists = model.encode([\"data scientists\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fef1a1-04bc-47da-b687-c4603ec69bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(room_engineers, room_scientists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3403c-9299-410c-a860-57455b7cad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(engineers, scientists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4e69d-9efa-42df-88e3-7640089ec8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_room = room_engineers - engineers + scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5031770-153c-4f92-8228-c01515b43bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(new_room, room_scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa837b98-17ff-486e-ac30-a4b4f794af7b",
   "metadata": {},
   "source": [
    "## With that background, let's populate our Chroma database\n",
    "\n",
    "### By calculating vectors for 400,000 scraped products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8f101-9c81-462d-be2e-9b479831857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the collection exists; if not, create it\n",
    "\n",
    "collection_name = \"products\"\n",
    "existing_collection_names = [collection.name for collection in client.list_collections()]\n",
    "\n",
    "if collection_name not in existing_collection_names:\n",
    "    collection = client.create_collection(collection_name)\n",
    "    for i in tqdm(range(0, len(train), 1000)):\n",
    "        documents = [item.text for item in train[i: i+1000]]\n",
    "        vectors = model.encode(documents).astype(float).tolist()\n",
    "        metadatas = [{\"category\": item.category, \"price\": item.price} for item in train[i: i+1000]]\n",
    "        ids = [f\"doc_{j}\" for j in range(i, i+1000)]\n",
    "        collection.add(\n",
    "            ids=ids,\n",
    "            documents=documents,\n",
    "            embeddings=vectors,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "collection = client.get_or_create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65375e1-a8eb-4203-b8f1-dfff69a693cc",
   "metadata": {},
   "source": [
    "# Let's visualize the vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c3b08-dc89-4995-a25c-041417ec9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is very fun turning this up to 400_000 and seeing the full dataset visualized,\n",
    "# but it almost crashes my box every time so do that at your own risk!! 5_000 is safe!\n",
    "\n",
    "MAXIMUM_DATAPOINTS = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653565a-6405-4c5a-b925-7e14a17bf2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['Appliances', 'Automotive', 'Cell_Phones_and_Accessories', 'Electronics','Musical_Instruments', 'Office_Products', 'Tools_and_Home_Improvement', 'Toys_and_Games']\n",
    "COLORS = ['cyan', 'blue', 'brown', 'orange', 'yellow', 'green' , 'purple', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a754334-69ef-4b4f-92c7-d7da89457f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'], limit=MAXIMUM_DATAPOINTS)\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "categories = [metadata['category'] for metadata in result['metadatas']]\n",
    "colors = [COLORS[CATEGORIES.index(c)] for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30b5e9-7dd9-45c1-a9a7-74cb22cdef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a 2D chart\n",
    "# TSNE stands for t-distributed Stochastic Neighbor Embedding - it's a common technique for reducing dimensionality of data\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
    "reduced_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a97fc5-9f44-4f1d-a253-8c8f0bcd9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=4, color=colors, opacity=0.7),\n",
    "    text=[f\"Category: {c}<br>Text: {d[:50]}...\" for c, d in zip(categories, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vectorstore Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y'),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb35e3-bd0d-4569-872b-34bea8316675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42, n_jobs=-1)\n",
    "reduced_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361c151-9f1b-4652-9204-695baf3860d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color=colors, opacity=0.7),\n",
    "    text=[f\"Category: {c}<br>Text: {d[:50]}...\" for c, d in zip(categories, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f14728-b797-49ed-9aad-e98ea6946b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - set up OpenAI, Ollama and DeepSeek\n",
    "\n",
    "# OpenAI\n",
    "openai = OpenAI()\n",
    "\n",
    "# Ollama\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# DeepSeek\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "deepseek_via_openai_client = OpenAI(api_key=deepseek_api_key,base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270b0ad-5a8f-4e54-a852-f16992314e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test pickle file\n",
    "\n",
    "with open('../test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a25b1-f93c-4a75-9999-09e262f9abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to give some context to DeepSeek by selecting 5 products with similar descriptions\n",
    "\n",
    "def make_context(similars, prices):\n",
    "    message = \"To provide some context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(similars, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b57490-060d-47ff-9cf0-2b61b455bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(item, similars, prices):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = make_context(similars, prices)\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3730c-5424-4d58-8c0a-fb1f03209f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cccac3-c0de-4d36-9803-20c8bd1762fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(item):\n",
    "    system_message = \"You rewrite product descriptions in a format most suitable for finding similar products in a Knowledge Base\"\n",
    "    user_message = \"Please write a short 2-3 sentence description of the following product; your description will be used to find similar products so it should be comprehensive and only about the product. Details:\\n\"\n",
    "    user_message += item\n",
    "    user_message += \"\\n\\nNow please reply only with the short description, with no introduction\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": user_message}]\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=\"llama3.2\",\n",
    "        messages=messages,\n",
    "        seed=42\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b40d36-2f53-4d72-84bf-74250e65dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(item):\n",
    "    user_message = \"Write 2-3 sentences about this product. This will be used to find similar products so it should be comprehensive and only about the product. Details:\\n\"\n",
    "    user_message += item\n",
    "    user_message += \"\\n\\nReply only with the short description, no introduction\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=\"llama3.2\",\n",
    "        messages=messages,\n",
    "        seed=42\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99ce28-7e42-45df-9aa3-e115332f9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(item):\n",
    "    text = preprocess(item.text)\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471584f-4998-469f-8c7f-cd7ffc74b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars(item):\n",
    "    vec = vector(item)\n",
    "    results = collection.query(query_embeddings=vec.astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "    return documents, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37742d64-0007-4259-8175-212ebb50fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1370ee5-8e15-4c2f-a009-39be2ba1eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preprocess(test[1].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25d64b-655c-4680-8a2a-b4158abf45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, prices = find_similars(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070e315-dbea-4dc2-8891-395848e7dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_context(documents, prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700ba02-a84b-432b-896a-29de50b85569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function that extracts a price from a response from GPT-4.1-mini\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce59e40-391b-4e52-b190-ef917b2baaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price(\"blah blah the price is $99.99 blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ab130-b6d8-4356-9704-687c9bc2636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for gpt-4.1\n",
    "\n",
    "def gpt_4_1_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\", \n",
    "        messages=messages_for(item, documents, prices),\n",
    "        seed=42,\n",
    "        max_tokens=8\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a6278-2da5-4bf8-b733-2947736feb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much does the Fan Clutch in test[1] actually cost, on Amazon?\n",
    "\n",
    "test[1].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30586f2-6b84-4750-acf5-a113ac9ccb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's call GPT-4o-mini using RAG, passing in 5 similar items from our Chroma datastore\n",
    "\n",
    "gpt_4_1_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961a9d3-0b59-4523-b555-f29dacd87ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try DeepSeek-V3 \n",
    "\n",
    "def deepseek_api_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    response = deepseek_via_openai_client.chat.completions.create(\n",
    "        model=\"deepseek-chat\", \n",
    "        messages=messages_for(item, documents, prices),\n",
    "        seed=42,\n",
    "        max_tokens=8\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aaf494-549c-473d-9802-75cc96704e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015b313-607d-47af-b5a7-f67d473d443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(gpt_4_1_rag, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2684714-e6d0-47d6-bf31-87fe349fc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293f0a8-7097-4744-a2e9-7da5268406a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from price_agents.frontier_agent import FrontierAgent\n",
    "\n",
    "agent = FrontierAgent(collection)\n",
    "agent.price(\"Quadcast HyperX condenser mic, connects via usb-c to your computer for crystal clear audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043d5e4-ec42-4fa0-9344-28a856d4f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.price(\"Shure MV7+ professional podcaster microphone with usb-c and XLR outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de4cf6-cc77-4060-9245-20b0992dcd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
